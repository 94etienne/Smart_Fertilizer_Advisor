{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42f1d3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (accuracy_score, classification_report, \n",
    "                            confusion_matrix, mean_squared_error, r2_score)\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier, \n",
    "                             RandomForestRegressor, GradientBoostingRegressor)\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_regression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import joblib  # For saving models\n",
    "import pickle  # Alternative for saving models\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2937c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  created_at  entry_id  Moisture  Temperature   EC   pH   N  \\\n",
      "0  2025-03-25T13:29:59+00:00       462      31.1         28.3  320  6.2  28   \n",
      "1  2025-03-25T13:30:16+00:00       463      31.1         28.3  319  6.2  28   \n",
      "2  2025-03-25T13:30:39+00:00       464      31.1         28.3  319  6.2  28   \n",
      "3  2025-03-25T13:31:02+00:00       465      31.1         28.3  319  6.1  27   \n",
      "4  2025-03-25T13:33:59+00:00       466      30.7         28.2  317  6.2  27   \n",
      "\n",
      "     P    K Fertilizer  kg/ha  \n",
      "0  111  103       Urea  126.0  \n",
      "1  111  103       Urea  126.0  \n",
      "2  111  103       Urea  126.0  \n",
      "3  110  103       Urea  121.5  \n",
      "4  110  102       Urea  121.5  \n",
      "\n",
      "Columns: Index(['created_at', 'entry_id', 'Moisture', 'Temperature', 'EC', 'pH', 'N',\n",
      "       'P', 'K', 'Fertilizer', 'kg/ha'],\n",
      "      dtype='object')\n",
      "\n",
      "Missing values:\n",
      " created_at     0\n",
      "entry_id       0\n",
      "Moisture       0\n",
      "Temperature    0\n",
      "EC             0\n",
      "pH             0\n",
      "N              0\n",
      "P              0\n",
      "K              0\n",
      "Fertilizer     0\n",
      "kg/ha          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('Dataset_for_Models.csv')\n",
    "\n",
    "# Initial inspection\n",
    "print(df.head())\n",
    "print(\"\\nColumns:\", df.columns)\n",
    "print(\"\\nMissing values:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f680bc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "df = df.drop(['created_at', 'entry_id'], axis=1)\n",
    "\n",
    "# Define features and transformers\n",
    "numeric_features = ['Moisture', 'Temperature', 'EC', 'pH', 'N', 'P', 'K']\n",
    "categorical_features = ['Fertilizer']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# Encode target variable (Fertilizer)\n",
    "le = LabelEncoder()\n",
    "df['Fertilizer'] = le.fit_transform(df['Fertilizer'])\n",
    "\n",
    "# Split data into features and targets\n",
    "X = df.drop(['Fertilizer', 'kg/ha'], axis=1)\n",
    "y_class = df['Fertilizer']\n",
    "y_reg = df['kg/ha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dd41dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_class_train, y_class_test, y_reg_train, y_reg_test = train_test_split(\n",
    "    X, y_class, y_reg, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1de855cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For classification\n",
    "selector_class = SelectKBest(score_func=f_classif, k='all')\n",
    "X_train_class = selector_class.fit_transform(X_train, y_class_train)\n",
    "X_test_class = selector_class.transform(X_test)\n",
    "\n",
    "# For regression\n",
    "selector_reg = SelectKBest(score_func=mutual_info_regression, k='all')\n",
    "X_train_reg = selector_reg.fit_transform(X_train, y_reg_train)\n",
    "X_test_reg = selector_reg.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58e0ce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning for best classifier\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "grid_search_class = GridSearchCV(RandomForestClassifier(random_state=42),\n",
    "                               param_grid_rf, cv=5, scoring='accuracy')\n",
    "grid_search_class.fit(X_train_class, y_class_train)\n",
    "best_class_model = grid_search_class.best_estimator_\n",
    "\n",
    "# Save the best classification model\n",
    "joblib.dump(best_class_model, 'best_classification_model.pkl')\n",
    "# Alternative: pickle.dump(best_class_model, open('best_class_model.pkl', 'wb'))\n",
    "\n",
    "# Also save the label encoder\n",
    "joblib.dump(le, 'label_encoder.pkl')\n",
    "\n",
    "# Evaluate all classification models\n",
    "for name, model in class_models.items():\n",
    "    model.fit(X_train_class, y_class_train)\n",
    "    y_pred = model.predict(X_test_class)\n",
    "    # Evaluation code remains the same..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a71c36f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_models = {\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
    "    'Support Vector': SVR()\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning for best regressor\n",
    "param_grid_rf_reg = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "grid_search_reg = GridSearchCV(RandomForestRegressor(random_state=42),\n",
    "                             param_grid_rf_reg, cv=5, scoring='r2')\n",
    "grid_search_reg.fit(X_train_reg, y_reg_train)\n",
    "best_reg_model = grid_search_reg.best_estimator_\n",
    "\n",
    "# Save the best regression model\n",
    "joblib.dump(best_reg_model, 'best_regression_model.pkl')\n",
    "\n",
    "# Evaluate all regression models\n",
    "for name, model in reg_models.items():\n",
    "    model.fit(X_train_reg, y_reg_train)\n",
    "    y_pred = model.predict(X_test_reg)\n",
    "    # Evaluation code remains the same..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94fe4529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overfitting Check for RandomForestClassifier:\n",
      "Train Score: 1.0000\n",
      "Test Score: 1.0000\n",
      "No significant overfitting or underfitting detected.\n",
      "\n",
      "Overfitting Check for GradientBoostingClassifier:\n",
      "Train Score: 1.0000\n",
      "Test Score: 1.0000\n",
      "No significant overfitting or underfitting detected.\n",
      "\n",
      "Overfitting Check for KNeighborsClassifier:\n",
      "Train Score: 1.0000\n",
      "Test Score: 1.0000\n",
      "No significant overfitting or underfitting detected.\n",
      "\n",
      "Overfitting Check for RandomForestRegressor:\n",
      "Train Score: 1.0000\n",
      "Test Score: 1.0000\n",
      "No significant overfitting or underfitting detected.\n",
      "\n",
      "Overfitting Check for GradientBoostingRegressor:\n",
      "Train Score: 1.0000\n",
      "Test Score: 1.0000\n",
      "No significant overfitting or underfitting detected.\n",
      "\n",
      "Overfitting Check for SVR:\n",
      "Train Score: 0.1645\n",
      "Test Score: 0.1662\n",
      "No significant overfitting or underfitting detected.\n"
     ]
    }
   ],
   "source": [
    "def check_overfitting(model, X_train, y_train, X_test, y_test, task='classification'):\n",
    "    if task == 'classification':\n",
    "        train_score = model.score(X_train, y_train)\n",
    "        test_score = model.score(X_test, y_test)\n",
    "    else:\n",
    "        train_score = model.score(X_train, y_train)\n",
    "        test_score = model.score(X_test, y_test)\n",
    "    \n",
    "    print(f\"\\nOverfitting Check for {type(model).__name__}:\")\n",
    "    print(f\"Train Score: {train_score:.4f}\")\n",
    "    print(f\"Test Score: {test_score:.4f}\")\n",
    "    \n",
    "    if abs(train_score - test_score) > 0.2:\n",
    "        if train_score > test_score:\n",
    "            print(\"Warning: Possible overfitting!\")\n",
    "        else:\n",
    "            print(\"Warning: Possible underfitting!\")\n",
    "    else:\n",
    "        print(\"No significant overfitting or underfitting detected.\")\n",
    "\n",
    "# Check for classification models\n",
    "for name, model in class_models.items():\n",
    "    check_overfitting(model, X_train_class, y_class_train, X_test_class, y_class_test)\n",
    "\n",
    "# Check for regression models\n",
    "for name, model in reg_models.items():\n",
    "    check_overfitting(model, X_train_reg, y_reg_train, X_test_reg, y_reg_test, 'regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b634194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions for new samples using saved models:\n",
      "\n",
      "Sample 1:\n",
      "Moisture        31.1\n",
      "Temperature     28.3\n",
      "EC             320.0\n",
      "pH               6.2\n",
      "N               28.0\n",
      "P              111.0\n",
      "K              103.0\n",
      "Name: 0, dtype: float64\n",
      "Predicted Fertilizer: Urea\n",
      "Predicted kg/ha: 126.00\n",
      "\n",
      "Sample 2:\n",
      "Moisture        32.1\n",
      "Temperature     27.5\n",
      "EC             325.0\n",
      "pH               6.3\n",
      "N               29.0\n",
      "P              115.0\n",
      "K              105.0\n",
      "Name: 1, dtype: float64\n",
      "Predicted Fertilizer: Urea\n",
      "Predicted kg/ha: 194.09\n",
      "\n",
      "Sample 3:\n",
      "Moisture        29.8\n",
      "Temperature     28.3\n",
      "EC             310.0\n",
      "pH               6.0\n",
      "N               26.0\n",
      "P              108.0\n",
      "K              100.0\n",
      "Name: 2, dtype: float64\n",
      "Predicted Fertilizer: Urea\n",
      "Predicted kg/ha: 117.00\n"
     ]
    }
   ],
   "source": [
    "# Create some new samples\n",
    "new_samples = pd.DataFrame({\n",
    "    'Moisture': [31.1, 32.1, 29.8],\n",
    "    'Temperature': [28.3, 27.5, 28.3],\n",
    "    'EC': [320, 325, 310],\n",
    "    'pH': [6.2, 6.3, 6.0],\n",
    "    'N': [28, 29, 26],\n",
    "    'P': [111, 115, 108],\n",
    "    'K': [103, 105, 100]\n",
    "})\n",
    "\n",
    "# Load saved models for demonstration\n",
    "loaded_class_model = joblib.load('best_classification_model.pkl')\n",
    "loaded_reg_model = joblib.load('best_regression_model.pkl')\n",
    "loaded_le = joblib.load('label_encoder.pkl')\n",
    "\n",
    "# Preprocess new samples\n",
    "new_samples_class = selector_class.transform(new_samples)\n",
    "new_samples_reg = selector_reg.transform(new_samples)\n",
    "\n",
    "# Make predictions\n",
    "print(\"\\nPredictions for new samples using saved models:\")\n",
    "for i, sample in new_samples.iterrows():\n",
    "    print(f\"\\nSample {i+1}:\")\n",
    "    print(sample)\n",
    "    \n",
    "    # Classification prediction\n",
    "    fert_pred = loaded_class_model.predict(new_samples_class[i:i+1])\n",
    "    print(f\"Predicted Fertilizer: {loaded_le.inverse_transform(fert_pred)[0]}\")\n",
    "    \n",
    "    # Regression prediction\n",
    "    kg_pred = loaded_reg_model.predict(new_samples_reg[i:i+1])\n",
    "    print(f\"Predicted kg/ha: {kg_pred[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46273a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importance for Classification:\n",
      "\n",
      "Feature Importance for Regression:\n"
     ]
    }
   ],
   "source": [
    "# For classification\n",
    "print(\"\\nFeature Importance for Classification:\")\n",
    "feature_imp_class = pd.Series(best_class_model.feature_importances_,\n",
    "                             index=X.columns[selector_class.get_support()])\n",
    "# Plotting code remains the same...\n",
    "\n",
    "# For regression\n",
    "print(\"\\nFeature Importance for Regression:\")\n",
    "feature_imp_reg = pd.Series(best_reg_model.feature_importances_,\n",
    "                           index=X.columns[selector_reg.get_support()])\n",
    "# Plotting code remains the same..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2c7ebf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "loaded_class_model = joblib.load('best_classification_model.pkl')\n",
    "loaded_reg_model = joblib.load('best_regression_model.pkl')\n",
    "loaded_le = joblib.load('label_encoder.pkl')\n",
    "\n",
    "# Make predictions\n",
    "fert_pred = loaded_class_model.predict(new_samples)\n",
    "kg_pred = loaded_reg_model.predict(new_samples)\n",
    "fert_name = loaded_le.inverse_transform(fert_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea08e20a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60a70ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
